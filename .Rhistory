n <- 10000
pi
generated_numbers <- rep(0, n)
?rnorm
?apply
?sapply
generated_numbers <- rnorm(10000, 0, 1)
exp(generated_numbers)
exp(-generated_numbers)
exp(generated_numbers)
exp(-generated_numbers)
exp((-generated_numbers))
exp((-generated_numbers)/2)
sum(exp((-generated_numbers)/2))
sum(exp((-generated_numbers)/2))/((sqrt(2*pi))*n)
library(tidyverse)
test <- sum(exp((-generated_numbers)/2))/((sqrt(2*pi))*n)
rm(test)
?select
select(generated_numbers, >= 0 & =< 1)
generated_numbers %>% select(> 0)
generated_numbers %>% select( . > 0)
generated_numbers %>% select(generated_numbers > 0)
generated_numbers %>% select(where(generated_numbers > 0))
subset(generated_numbers, < 0)
subset(generated_numbers, generated_numbers
< 0)
subset(generated_numbers, generated_numbers >= 0 & )
subset(generated_numbers, generated_numbers >= 0)
subset(generated_numbers, generated_numbers >= 0 & generated_numbers <= 1 )
subset(generated_numbers, generated_numbers >= 0 & generated_numbers =< 1 )
subset(generated_numbers, generated_numbers >= 0 & generated_numbers < 1 )
subset(generated_numbers, generated_numbers >= 0 && generated_numbers < 1 )
subset(generated_numbers, generated_numbers >= 0 & generated_numbers < 1 )
generated_numbers %>% subset(generated_numbers >= 0) %>% subset(generated_numbers < 1)
generated_numbers %>% subset(generated_numbers >= 0) %>% subset(generated_numbers =< 1)
generated_numbers %>% subset(generated_numbers >= 0) %>% subset(generated_numbers <= 1)
generated_numbers %>% subset(generated_numbers >= 0 & generated_numbers <= 1)
library(tidyverse)
MonteCarloIntegration <- function(LB = 0, UB = 1, n = 10000) {
library(tidyverse)
generated_numbers <- rnorm(n = n, mean = 0, sd = 1)
generated_numbers <- generated_numbers %>% subset(generated_numbers >= 0 & generated_numbers <= 1)
solved_integral <- sum(exp((-generated_numbers)/2))/((sqrt(2*pi))*n)
return(solved_integral)
}
MonteCarloIntegration(0, 1, 10000)
MonteCarloIntegration(0, 1, 100000)
MonteCarloIntegration(0, 1, 10000000)
MonteCarloIntegration(0, 1, 100000000)
?rnorm
MonteCarloIntegration <- function(LB = 0, UB = 1, n = 10000) {
library(tidyverse)
generated_numbers <- rnorm(n = n, mean = 0, sd = 1)
generated_numbers <- generated_numbers %>% subset(generated_numbers >= LB & generated_numbers <= UB)
solved_integral <- sum(exp((-generated_numbers)/2))/((sqrt(2*pi))*length(generated_numbers))
return(solved_integral)
}
MonteCarloIntegration(0, 1, 10000)
MonteCarloIntegration(0, 1, 100000)
MonteCarloIntegration(0, 1, 1000000)
MonteCarloIntegration(0, 1, 1000000)
MonteCarloIntegration(0, 1, 10000000)
?exp
?subset
?rnorm
## Create a function that requires three inputs:
## a lower and upper bound of the integral, and the amount of numbers to be drawn
## pseudo-randomly (by default these numbers are 0, 1 and 10000)
MonteCarloIntegration <- function(LB = 0, UB = 1, n = 10000) {
## The package then loads tidyverse, as it uses the pipeline function
library(tidyverse)
## Then it generates n random observations from a standard normal distribution
## (a normal distribution with mean = 0 and standard deviation = 1)
generated_numbers <- rnorm(n = n, mean = 0, sd = 1)
## From these observations, the ones within the integral limit are then subsetted
generated_numbers <- generated_numbers %>% subset(generated_numbers >= LB & generated_numbers <= UB)
## And with these numbers, the integral is approximated through the following function:
solved_integral <- sum(exp((-generated_numbers^2)/2))/((sqrt(2*pi))*length(generated_numbers))
## Finally, the function should return the value of the approximated integral
return(solved_integral)
}
MonteCarloIntegration(0, 1, 1000000)
MonteCarloIntegration(0, 1, 1000)
MonteCarloIntegration(0, 1, 10000)
MonteCarloIntegration(0, 1, 100000)
MonteCarloIntegration(0, 1, 1000000)
MonteCarloIntegration(0, 1, 100000)
MonteCarloIntegration(0, 1, 10000)
MonteCarloIntegration(0, 2, 10000)
MonteCarloIntegration(0, 2, 10000)
MonteCarloIntegration(LB = 0, UB = 2, n = 10000)
MonteCarloIntegration(LB = 0, UB = 3, n = 10000)
MonteCarloIntegration(LB = 0, UB = 100, n = 10000)
MonteCarloIntegration(LB = -1, UB = 0, n = 10000)
MonteCarloIntegration(LB = -2, UB = 2, n = 10000)
MonteCarloIntegration(LB = -2, UB = 1, n = 10000)
MonteCarloIntegration(LB = 0, UB = 1, n = 10000)
MonteCarloIntegration(LB = -1, UB = 1, n = 10000)
## Create a function that requires three inputs:
## a lower and upper bound of the integral, and the amount of numbers to be drawn
## pseudo-randomly (by default these numbers are 0, 1 and 10000)
MonteCarloIntegration <- function(LB = 0, UB = 1, n = 10000) {
## The package then loads tidyverse, as it uses the pipeline function
library(tidyverse)
## Then it generates n random observations from a standard normal distribution
## (a normal distribution with mean = 0 and standard deviation = 1)
generated_numbers <- rnorm(n = n, mean = 0, sd = 1)
## From these observations, the ones within the integral limits are then subsetted
generated_numbers <- generated_numbers %>% subset(generated_numbers >= LB & generated_numbers <= UB)
## And with these numbers, the integral is approximated through the following function:
solved_integral <- sum(exp((-(generated_numbers^2))/2))/((sqrt(2*pi))*length(generated_numbers))
## Finally, the function should return the value of the approximated integral
return(solved_integral)
}
MonteCarloIntegration(LB = 1, UB = 1, n = 10000)
MonteCarloIntegration(LB = 0, UB = 1, n = 10000)
MonteCarloIntegration(LB = -1, UB = 1, n = 10000)
MonteCarloIntegration(LB = 0, UB = 1, n = 10000)
MonteCarloIntegration(LB = 0, UB = 2, n = 10000)
## Create a function that requires three inputs:
## a lower and upper bound of the integral, and the amount of numbers to be drawn
## pseudo-randomly (by default these numbers are 0, 1 and 10000)
MonteCarloIntegration <- function(LB = 0, UB = 1, n = 10000) {
## The package then loads tidyverse, as it uses the pipeline function
library(tidyverse)
## Then it generates n random observations from a standard normal distribution
## (a normal distribution with mean = 0 and standard deviation = 1)
generated_numbers <- rnorm(n = n, mean = 0, sd = 1)
## From these observations, the ones within the integral limits are then subsetted
generated_numbers <- generated_numbers %>% subset(generated_numbers >= LB & generated_numbers <= UB)
## And with these numbers, the integral is approximated through the following function:
solved_integral <- sum(exp(-((generated_numbers^2))/2))/((sqrt(2*pi))*length(generated_numbers))
## Finally, the function should return the value of the approximated integral
return(solved_integral)
}
MonteCarloIntegration(LB = 0, UB = , n = 10000)
MonteCarloIntegration(LB = -1, UB = 1, n = 10000)
MonteCarloIntegration(LB = 0, UB = 1, n = 10000)
?runif
test <- runif(10000, 0, 1)
sum(exp(-((test^2))/2))/((sqrt(2*pi))*length(test))
test <- runif(10000, 0, 2)
sum(exp(-((test^2))/2))/((sqrt(2*pi))*length(test))
test <- runif(10000, 0, 1)
sum(exp(-((test^2))/2))/((sqrt(2*pi))*length(test))
rm(test)
install.packages("jags")
install.packages("rjags")
load(rjags)
load("rjags")
install.packages("rjags")
library(rjags)
install.packages("R2jags")
library(R2jags)
library(rjags)
library(rjags)
library(rjags)
install.packages(c("backports", "broom", "class", "cli", "DBI", "digest", "dplyr", "dtplyr", "fansi", "foreign", "fs", "generics", "glue", "jsonlite", "knitr", "lme4", "magrittr", "MASS", "Matrix", "nlme", "nloptr", "nnet", "openssl", "pillar", "Rcpp", "readr", "rlang", "rpart", "spatial", "stringi", "tidyr", "tinytex", "vroom", "xfun", "xml2", "yaml"))
library(rjags)
.Platform$pkgType
library(rjags)
install.packages("rjags", type="source")
library(rjags)
## Part 1: Data and packages
library(tidyverse)
library(qgraph)
## Collider-structure
varnames <- c("X","Y","Z")
Adj <- matrix(c(0,0,1,
0,0,1,
0,0,0), 3,3, byrow = TRUE,
dimnames = list(varnames,varnames))
qgraph(Adj,
labels = c("X","Y","Z"), # not necessary if Adj has dimnames
#you can provide a custom layout by giving the x-y co-ordinates of each node
layout = rbind(c(-1,-1),
c(1,-1),
c(0,1)))
## Fork-structure
Fork_Adj <- matrix(c(0,0,0,
0,0,0,
1,1,0), 3,3, byrow = TRUE,
dimnames = list(varnames, varnames))
qgraph(Fork_Adj,
layout = rbind(c(-1,-1),
c(1,-1),
c(0,1)))
## Mediator-structure
Mediator_Adj <- matrix(c(0,1,0,
0,0,1,
0,0,0), 3,3, byrow = TRUE,
dimnames = list(varnames, varnames))
qgraph(Mediator_Adj,
layout = rbind(c(-1,-1),
c(1,-1),
c(0,1)))
library(ggdag)
coldag <- dagify(
Z ~ X + Y,
exposure = "X", # the "cause" variable you are interested in
outcome = "Y", # the "effect" variable you are interested in
# optional: give co-ordinates of the variables in the plot
coords = list(x = c(X = -1, Y = 1, Z = 0),
y = c(X = 0, Y = 0, Z = 1))
)
ggdag_status(coldag) + theme_dag()
## Fork-structure with ggdag
forkdag <- dagify(
X + Y ~ Z
exposure = "X"
outcome = "Y"
)
## Fork-structure with ggdag
forkdag <- dagify(
X + Y ~ Z,
exposure = "X",
outcome = "Y"
)
## Fork-structure with ggdag
forkdag <- dagify(
X ~ Z,
Y ~ Z,
exposure = "X",
outcome = "Y",
coords = list(x = c(X = -1, Y = 1, Z = 0),
y = c(X = 0, Y = 0, Z = 1))
)
ggdag_status(forkdag) + theme_dag()
## Mediator-structure with ggdag
meddag <- dagify(
Y ~ X,
Z ~ Y,
exposure = "X",
outcome = "Y",
coords = list(x = c(X = -1, Y = 1, Z = 0),
y = c(X = 0, Y = 0, Z = 1))
)
ggdag_status(meddag) + theme_dag()
## Mediator-structure with ggdag
meddag <- dagify(
Y ~ X,
Z ~ Y,
exposure = "X",
outcome = "Y",
coords = list(x = c(X = -1, Y = 1, Z = 2),
y = c(X = 0, Y = 0, Z = 0))
)
ggdag_status(meddag) + theme_dag()
## Mediator-structure with ggdag
meddag <- dagify(
Y ~ X,
Z ~ Y,
exposure = "X",
outcome = "Y",
coords = list(x = c(X = -1, Y = 1, Z = 3),
y = c(X = 0, Y = 0, Z = 0))
)
ggdag_status(meddag) + theme_dag()
## Mediator-structure with ggdag
meddag <- dagify(
Y ~ X,
Z ~ Y,
exposure = "X",
outcome = "Z",
coords = list(x = c(X = -1, Y = 1, Z = 3),
y = c(X = 0, Y = 0, Z = 0))
)
ggdag_status(meddag) + theme_dag()
eddag <- dagify(
EA ~ CI,
AI ~ CI + EA + U,
Inc ~ EA + CI + AI + U ,
exposure = "EA", # the "cause" variable you are interested in
outcome = "Inc", # the "effect" variable you are interested in
# optional: give co-ordinates of the variables in the plot
coords = list(x = c(EA = -1,CI = 0,AI =0 ,Inc =1 , U = -1),
y = c(EA = 0,CI =1 ,AI = -1,Inc = 0, U = -1))
)
ggdag_status(eddag) + theme_dag()
adjustmentSets(eddag)
library(ggdag)
library(qgraph)
## Part 1: Data and packages
library(tidyverse)
adjustmentSets(eddag)
?adjustmentSets
library(daggity)
install.packages("daggity")
library(daggity)
library(dagitty)
library(dagitty)
adjustmentSets(eddag)
setwd("~/Documents/GitHub/Causal-Inference-SEM")
mdata <- readRDS("mdata.RDS")
View(mdata)
summary(lm(mal ~ income + health + net, data = mdata))
summary(lm(mal ~ Income + health + net, data = mdata))
maldag <- daggify(
mal ~ Income + net,
net ~ Income,
health ~ Income + mal,
exposure = "net",
outcome = "mal"
)
maldag <- dagify(
mal ~ Income + net,
net ~ Income,
health ~ Income + mal,
exposure = "net",
outcome = "mal"
)
ggdag_status(maldag) + theme_dag()
adjustmentSets(maldag)
summary(lm(mal ~ net + Income, data = mdata))
summary(lm(mal ~ Income + health + net, data = mdata))
summary(lm(mal ~ net + Income, data = mdata))
data <- readRDS("ex5_data.RDS")
Adj <- rbind(c(0,0,0,1,0,0,0,0,0),
c(0,0,1,1,0,0,0,0,0),
c(0,0,0,0,0,0,0,1,0),
c(0,0,0,0,1,1,0,0,0),
c(0,0,0,0,0,0,0,0,0),
c(0,0,0,0,0,0,1,1,0),
c(0,0,0,0,0,0,0,0,0),
c(0,0,0,0,0,0,0,0,1),
c(0,0,0,0,0,0,0,0,0))
names <- c("C", "A", "K", "X", "F", "D", "G", "Y", "H")
dimnames(Adj) = list(names,names)
laymat <- matrix(
c(-1,   1,
-.5,   1,
.5,   1,
-.75,   0,
-.75,  -1,
0,   0,
0,  -1,
1,   0,
1,  -1),9,2,byrow = T)
vsize =15; esize = 10; asize = 10
qgraph(Adj,
layout = laymat,
vsize =vsize, esize = esize, asize = asize)
library(CondIndTests)
library(dHSIC)
dhsic.test(data[,"C"], data[,"A"])
CondIndTest(data[,"X"], data[,"G"], data[,"D"])
## Two true conditional independence statements:
## A and F are independent given X
CondIndTest(data[, "A"], data[, "F"], data[, "X"])
## G and Y are independent given D
CondIndTest(data[, "G"], data[, "Y"], data[, "D"]) ## true!
## Two false conditional independence statements:
## G and Y are independent
dhsic.test(data[,"G"], data[,"Y"])
## A and F are independent
dhsic.test(data[,"A"], data[,"F"])
summary(lm(Y ~ X + A))
summary(lm(Y ~ X + A, data = data))
summary(lm(Y ~ X + A, data = as.data.frame(data)))
summary(lm(Y ~ X + K, data = as.data.frame(data)))
datadag <- dagify(
H ~ Y,
F ~ X,
G ~ D,
Y ~ D + K,
K ~ A,
X ~ C + A,
D ~ X,
exposure = "X",
outcome = "Y"
)
ggdag_status(datadag) + theme_dag()
datadag <- dagify(
H ~ Y,
F ~ X,
G ~ D,
Y ~ D + K,
K ~ A,
X ~ C + A,
D ~ X,
exposure = "X",
outcome = "Y",
coords = list(x = c(X = 0, F = 0, D = 1, G = 1, Y = 3, H = 3, A = 0.5, C = -0.5, K = 2),
y = c(X = 1, F = 0, D = 1, G = 0, Y = 1, H = 0, A = 2, C = 2, K = 2))
)
ggdag_status(datadag) + theme_dag()
adjustmentSets(datadag)
adjustmentSets(datadag, type = "all")
scmdag <- dagify(
X ~ Z
Y ~ X + Z
)
scmdag <- dagify(
X ~ Z,
Y ~ X + Z
)
ggdag_status(scmdag) + theme_dag()
scmdag <- dagify(
X ~ Z,
Y ~ X + Z,
exposure = "Z",
outcome = "Y"
)
ggdag_status(scmdag) + theme_dag()
scmdag <- dagify(
X ~ Z,
Y ~ X + Z,
exposure = "Z",
outcome = "Y",
coords = list(x = c(X = 0, Y = 2, Z = 1),
y = c(X = 0, Z = 0, Y = 1))
)
ggdag_status(scmdag) + theme_dag()
scmdag <- dagify(
X ~ Z,
Y ~ X + Z,
exposure = "Z",
outcome = "Y",
coords = list(x = c(X = 0, Y = .5, Z = 1),
y = c(X = 0, Z = 0, Y = .5))
)
ggdag_status(scmdag) + theme_dag()
n <- 1000
Z <- rnorm(n = n, mean = 0, sd = 1)
X <- 2*Z + rnorm(n = n, mean = 0, sd = 1)
Y <- X + 2*Z + rnorm(n = n, mean = 0, sd = 1)
summary(lm(Y ~ X))
summary(lm(Y ~ X + Z))
data <- readRDS("data_cd_ex1.RDS")
View(data)
data <- as.data.frame(readRDS("data_cd_ex1.RDS"))
View(data)
library(ppcor)
library(ppcor)
cor.test(data)
data <- readRDS("data_cd_ex1.RDS")
cor.test(data)
data <- readRDS("data_cd_ex1.RDS")
cor.test(x = data)
cor.test(x = data,y = data)
cor.test(X1, X2, data = data)
cor.test(X1, X2)
?cor.test
cor.test(data$X1, data$X2)
View(data)
data <- readRDS("data_cd_ex1.RDS")
library(ppcor)
cor.test(data$X1, data$X2)
data <- as.data.frame(readRDS("data_cd_ex1.RDS"))
cor.test(data, data$X2)
cor.test(data$X1, data$X2)
cor.test(data$X1, data$X3)
cor.test(data$X1, data$X4)
cor.test(data$X3, data$X4)
cor.test(data$X2, data$X3)
cor.test(data$X2, data$X3)
cor.test(data$X2, data$X4)
cor.test(data$X3, data$X4)
?pcor.test
pcor.test(data$X1, data$X2, data$X3)
pcor.test(data$X1, data$X2, data$X4)
pcor.test(data$X1, data$X3, data$X2)
pcor.test(data$X1, data$X3, data$X4)
pcor.test(data$X1, data$X4, data$X2)
pcor.test(data$X1, data$X4, data$X3)
pcor.test(data$X2, data$X3, data$X1)
pcor.test(data$X2, data$X3, data$X4)
pcor.test(data$X2, data$X3, data$X4)
pcor.test(data$X2, data$X4, data$X1)
pcor.test(data$X2, data$X4, data$X3)
pcor.test(data$X3, data$X4, data$X1)
pcor.test(data$X4, data$X4, data$X2)
pcor.test(data$X3, data$X4, data$X1)
pcor.test(data$X4, data$X4, data$X2)
pcor.test(data$X3, data$X4, data$X2)
pcor(data$X1, data$X2)
pcor(data$X1, data$X3)
pcor(data)
